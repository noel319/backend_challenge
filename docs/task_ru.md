# Backend test task

Ожидаемое время выполнения: 3-5 часов

На вход будет дано краткое описание проблемы + некоторые ограничения и требования, чтобы задать общий вектор работы. 

Также будет перечислен набор рекомендуемых технологий, так как мы ожидаем, что кандидат умеет работать с нашим стеком, либо способен/способна оперативно разобраться.

На выходе ожидается публичный репозиторий (созданный из этого репозитория-шаблона) отправьте ссылку на
[форму](https://hiretechfast.typeform.com/to/QZ55qiDi)


Репозиторий должен содержать:

- краткую инструкцию по подъему и запуску проекта после внесенных изменений
- код с тестами, логированием и трейсингом (можно использовать sentry transactions)
- документацию, описывающую примененное техническое решение и дизайн (можно нарисовать схему, но не обязательно)

## Stack

- Python
- Django
- pytest (pytest-django preferred for fixtures)
- Docker & docker-compose
- PostgreSQL
- Celery & Celery beat
- ClickHouse (уже установлен в докере)

## Problem

Во время работы наше приложение пишет event-логи, которые затем используются для аналитики, разбора инцидентов и аудитов безопасности.

Для хранения этих логов используется колоночная аналитическая база данных ClickHouse и т.н. One Big Table (далее OBT) – широкая таблица, которая содержит следующий набор колонок (в будущем набор колонок может быть расширен):

```
event_type: String
event_date_time: DateTime
environment: String
event_context: String // JSON field with unstructured payload
metadata_version: UInt64 // for versioning purposes
```

В текущей реализации запись происходит синхронно из кода приложения напрямую в CH, см. пример в `CreateUser` use case:

С таким подходом возникли проблемы, некоторые из которых:

- из-за отсутствия транзакционности события терялись в случае, если веб-воркер приложения умирал между завершением выполнения бизнес-логики и записью в CH
- сетевые ошибки при записи в CH приводили к ошибкам на UI, что ухудшало UX
- CH страдал от большого количества построчных записей (см. https://clickhouse.com/blog/common-getting-started-issues-with-clickhouse#many-small-inserts)

Необходимо реализовать механизм записи, который позволит избавиться от перечисленных проблем, а также упростить написание и тестирование бизнес-логики через понятный интерфейс публикации событий

**Restrictions and requirements:**

- для простоты системы мы не хотим использовать Kafka для event streaming.
- мы не хотим завязываться на специфичные фичи Clickhouse, такие как RabbitMQ/Kafka engine для вставки событий, т.к. есть шанс, что CH в последствие будет заменен на другую базу
- мы так же не хотим использовать внешние файловые хранилища, типа S3
- поле event_context будет содержать JSON произвольного формата и веса (up to N MBytes). Кидать их напрямую в очередь может быть не лучшей идеей
- `transactional outbox pattern` может пригодиться для данной задачи
- в целом хочется иметь как можно более просто решение на предсказуемом стеке технологий, чтобы было проще поддерживать, мониторить и дебажить
